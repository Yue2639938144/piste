# 新一代生物分子互作预测模型研发路线图

本文档基于对先前规划文档（需求规格、架构设计、数据策略、训练优化方案、可视化方案、部署方案）的综合分析，提出一个多阶段的研发路线图，旨在为新一代 TCR-HLA-Pep 互作预测模型的开发提供清晰的指引。

## 1. 项目概述与目标

本项目旨在开发一个基于 Transformer 架构、模块化、可预训练并支持联合优化的新一代 TCR-HLA-Pep 三元组互作预测模型。核心目标是提升预测精度，支持全长序列输入，融合多种注意力机制，并提供用户友好的预测工具和可视化功能。

## 2. 整体研发阶段划分

根据项目复杂度和依赖关系，我们将研发过程划分为以下主要阶段：

| 阶段序号 | 阶段名称                 | 主要目标                                                                                                | 相对时间投入 |
| :------- | :----------------------- | :------------------------------------------------------------------------------------------------------ | :----------- |
| Phase 1  | **规划与数据基石**       | 明确所有技术细节，完成高质量、结构化的数据准备                                                            | 15%          |
| Phase 2  | **核心模型组件实现**     | 构建 TCR-Pep 和 HLA-Pep 二元模型的关键模块及基础架构                                                        | 10%          |
| Phase 3  | **二元模型预训练与验证** | 独立训练和优化二元模型，验证核心组件有效性                                                              | 20%          |
| Phase 4  | **三元模型整合与框架构建** | 构建三元模型，实现特征融合、参数共享及联合优化基础框架                                                      | 15%          |
| Phase 5  | **联合优化与模型定型**   | 执行复杂的三元联合训练，调优整体模型性能，确定最终模型权重与阈值                                            | 25%          |
| Phase 6  | **模型终态评估**         | 在独立测试集上进行全面、公正的模型性能评估                                                              | 2%           |
| Phase 7  | **残基互作可视化功能**   | 实现模型解释性可视化工具                                                                                | 5%           |
| Phase 8  | **部署、打包与文档**     | 构建易于分发和使用的软件包及命令行工具，完善文档，准备开源                                              | 8%           |

---

## 3. 各阶段详细路线图

以下详细阐述每个阶段的关键任务、里程碑、预估时间投入及所需资源。

### Phase 1: 规划与数据基石

*   **目标:** 完成所有技术方案的细化设计，建立稳定可靠的数据处理与加载流程。
*   **主要任务:**
    - 细化模型架构设计，特别是全长序列 Encoder-Decoder 结构、注意力融合机制和联合优化框架的实现细节。
    - 搭建开发环境，安装所有必需的库（PyTorch/TensorFlow, NumPy, Pandas, Biopython 等）。
    - 执行数据收集、清洗、去冗余和标准化（基于 PISTE 数据）。
    - 实现氨基酸序列的索引化、生化属性编码、变长序列填充和注意力掩码生成逻辑。
    - 根据数据策略构建 TCR-Pep、HLA-Pep 和 TCR-HLA-Pep 的训练、验证、测试数据集，**重点实施基于序列相似性聚类的划分策略，避免数据泄露**。
    - 实现高效的数据加载器 (`DataLoader`)，支持批量处理变长序列和掩码。
    - 定义并搭建实验追踪和日志记录框架。
*   **关键里程碑:**
    - **M1.1:** 细化技术方案文档定稿。
    - **M1.2:** 开发环境搭建完成，核心库安装就绪。
    - **M1.3:** 原始数据清洗、去冗余及初步标准化完成。
    - **M1.4:** 数据预处理（索引化、填充、掩码、生化编码）流程实现并通过单元测试。
    - **M1.5:** 三个数据集（TCR-Pep, HLA-Pep, Trimer）按照序列相似性划分策略构建完成。
    - **M1.6:** 可用数据加载器，能够正确加载处理后的数据并生成带掩码的批次。
*   **相对时间投入:** 15%

---

### Phase 2: 核心模型组件实现

*   **目标:** 实现 TCR-Pep 和 HLA-Pep 二元模型的所有核心组件，能够进行基本的正向传播。
*   **主要任务:**
    - 实现基于 Transformer 的 Encoder 模块，支持变长序列输入和注意力掩码。
    - 实现融合物理滑动和数据驱动注意力的 Decoder (交互编码器) 模块。
    - 实现二元模型预测模块（全连接层）。
    - 实现 HLA-Pep 模型中的 pHLA 复合物表示生成逻辑。
    - 实现训练方案中指定的损失函数（加权交叉熵、焦点损失）。
    - 实现优化器配置及学习率调度器。
    - 编写模型的单元测试，验证各组件功能。
*   **关键里程碑:**
    - **M2.1:** Encoder 和 Decoder 模块代码实现完成并初步测试。
    - **M2.2:** TCR-Pep 模型类结构定义及正向传播逻辑实现。
    - **M2.3:** HLA-Pep 模型类结构定义及正向传播逻辑实现，包含 pHLA 表示输出。
    - **M2.4:** 损失函数和优化器配置代码实现。
    - **M2.5:** 核心模型组件通过单元测试。
*   **相对时间投入:** 10%

---

### Phase 3: 二元模型预训练与验证

*   **目标:** 独立训练和优化 TCR-Pep 和 HLA-Pep 模型，获得高质量的预训练权重，验证基础架构的有效性。
*   **主要任务:**
    - 实现二元模型训练循环 (`train_step`, `eval_step`)。
    - 实现早停机制。
    - 在 TCR-Pep 数据集上执行预训练。
    - 在 HLA-Pep 数据集上执行预训练。
    - 监控验证集性能指标 (AUC-ROC, F1, MCC)，进行模型调优或超参数调整。
    - 保存表现最佳的二元模型权重。
*   **关键里程碑:**
    - **M3.1:** 二元模型训练流程代码实现完成。
    - **M3.2:** TCR-Pep 模型预训练完成，最佳权重保存。
    - **M3.3:** HLA-Pep 模型预训练完成，最佳权重保存。
    - **M3.4:** 获得二元模型在各自验证集上的初步性能报告。
*   **相对时间投入:** 20% (计算资源消耗较大)

---

### Phase 4: 三元模型整合与框架构建

*   **目标:** 构建完整的 TCR-HLA-Pep 三元模型，整合预训练组件，并实现联合优化的基础训练框架。
*   **主要任务:**
    - 实现特征融合模块（拼接、线性变换等）。
    - 实现三元模型预测模块。
    - 构建 TCR-HLA-Pep 三元模型类，集成 TCR-Pep 和 HLA-Pep 模型（或其共享组件）。
    - 实现参数共享逻辑，确保二元模型组件在三元模型中参数是关联的。
    - 设计并实现联合损失函数，包括三元任务损失和二元辅助损失。
    - 实现循环联合优化的训练循环基础结构。
*   **关键里程碑:**
    - **M4.1:** 特征融合及三元预测模块实现。
    - **M4.2:** TCR-HLA-Pep 三元模型类定义完成，能够加载预训练权重。
    - **M4.3:** 联合损失函数代码实现。
    - **M4.4:** 联合优化训练循环基础结构（能够运行，可能未完全调通梯度回传）。
*   **相对时间投入:** 15%

---

### Phase 5: 联合优化与模型定型

*   **目标:** 运行并调优三元模型的联合训练过程，获得性能最优的最终模型权重和最佳分类阈值。
*   **主要任务:**
    - 执行 TCR-HLA-Pep 三元模型的联合优化训练。
    - 调优联合训练超参数（学习率、损失权重、冻结/解冻策略等）。
    - 监控三元模型在验证集上的性能 (AUC-ROC, F1, MCC)，应用早停机制。
    - 实现最佳阈值筛选功能，基于验证集性能确定最优分类阈值。
    - 根据验证集性能迭代优化模型架构或训练策略。
    - 保存最终的最佳模型权重和对应的最佳阈值。
*   **关键里程碑:**
    - **M5.1:** 三元模型联合优化训练流程稳定运行。
    - **M5.2:** 获得三元模型在验证集上的收敛性能，最佳模型权重保存。
    - **M5.3:** 最佳分类阈值筛选完成并记录。
    - **M5.4:** 获得三元模型在验证集上的最终性能报告。
*   **相对时间投入:** 25% (最核心的训练和调优阶段，计算资源和人力投入集中)

---

### Phase 6: 模型终态评估

*   **目标:** 在独立的测试集上对最终模型进行全面、公正的性能评估。
*   **主要任务:**
    - 加载最终的最佳三元模型权重和最佳阈值。
    - 在完全独立的测试数据集上执行模型推理。
    - 计算所有关键评估指标：AUC-ROC, AUC-PR, F1-score, MCC, Accuracy, Precision, Recall。
    - 生成详细的测试集性能评估报告，包括指标表格和 ROC/PR 曲线图。
*   **关键里程碑:**
    - **M6.1:** 完成测试集评估。
    - **M6.2:** 生成最终模型性能评估报告。
*   **相对时间投入:** 2%

---

### Phase 7: 残基互作可视化功能

*   **目标:** 实现用户需求中的残基互作可视化功能。
*   **主要任务:**
    - 开发模型推理时的注意力权重提取逻辑（特别是二元模型交互层的交叉注意力权重）。
    - 实现提取权重的后处理逻辑（移除填充、聚合多头）。
    - 实现基于注意力权重的热力图生成代码。
    - 设计并实现可视化结果的输出格式和接口。
*   **关键里程碑:**
    - **M7.1:** 注意力权重提取和处理代码实现完成。
    - **M7.2:** 残基互作热力图生成功能实现。
    - **M7.3:** 可视化功能通过测试，能够为指定的输入样本生成互作图。
*   **相对时间投入:** 5%

---

### Phase 8: 部署、打包与文档

*   **目标:** 将模型和代码打包成易于安装和使用的软件包，提供命令行工具，并完成所有文档，准备开源。
*   **主要任务:**
    - 实现 Linux 命令行接口 (`predict_cli.py`)，处理输入参数、文件读写、调用模型推理和输出结果。
    - 组织代码库结构，遵循标准 Python 包规范。
    - 创建 `setup.py` 或 `pyproject.toml` 文件，配置包元信息和命令行入口点。
    - 编写 `requirements.txt` 或 `environment.yml` 列出项目依赖。
    - 编写详细的 `README.md`，包含项目介绍、安装、使用示例（特别是 CLI 使用）、文档链接。
    - 编写用户文档和 API 文档（使用 Docstrings 和文档生成工具）。
    - 选择并添加开源许可证 (`LICENSE`)。
    - 规划并实施模型文件 (`.pkl`) 的版本控制策略（如 Git LFS 或外部托管）。
    - 设置基本的持续集成 (CI) 流程，运行测试和代码风格检查。
    - 准备贡献指南 (`CONTRIBUTING.md`) 和行为准则 (`CODE_OF_CONDUCT.md`)。
*   **关键里程碑:**
    - **M8.1:** Linux 命令行接口实现并集成模型推理逻辑。
    - **M8.2:** 代码库按照 Python 包结构组织完成。
    - **M8.3:** 打包配置文件 (`setup.py`/`pyproject.toml`, `requirements.txt`) 创建并验证。
    - **M8.4:** 核心文档 (`README.md`, `LICENSE`) 完成。
    - **M8.5:** 模型文件版本控制方案落地。
    - **M8.6:** CI 流程搭建完成并运行通过。
    - **M8.7:** 项目具备开源发布条件。
*   **相对时间投入:** 8%

---

## 4. 关键风险与缓解策略

*   **风险:** 联合优化策略实现复杂，梯度回传和参数共享可能引入难以调试的问题。
    *   **缓解:** 分阶段实现，先验证二元模型，再逐步构建三元模型和联合损失。从简单的联合训练配置开始（如先冻结二元编码器），逐步放开。利用可视化和日志详细追踪损失变化和梯度流动。
*   **风险:** 全长序列处理可能引入显著的计算开销，尤其在长序列数据集上。
    *   **缓解:** 仔细优化 Encoder-Decoder 实现，利用注意力掩码提高效率。探索更高效的长序列 Transformer 变体。考虑计算资源的扩充。
*   **风险:** 数据划分中未能完全避免序列相似性导致数据泄露，影响模型泛化能力。
    *   **缓解:** 投入足够时间在 Phase 1，采用严格的序列聚类和跨簇划分策略。在评估阶段对测试集进行额外的相似性检查，确保其独立性。
*   **风险:** 无法从模型中提取有效的残基互作信息进行可视化。
    *   **缓解:** 在模型设计阶段就考虑信息可提取性。在 Phase 4/5 训练过程中尝试提取并初步分析注意力权重，验证其生物学合理性，以便在 Phase 7 顺利进行。

## 5. 总结

本路线图提供了一个结构化、可执行的新一代 TCR-HLA-Pep 模型研发计划。通过清晰的阶段划分、具体的任务和里程碑、以及对资源和风险的预估，为项目团队提供了明确的行动指南。成功完成这些阶段将交付一个高性能、可解释、易于使用且具备开源潜力的生物分子互作预测模型。